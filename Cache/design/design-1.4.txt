eZ component: Cache, Design, 1.4
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
$Author$
$Revision$
$Date$
:Status: Draft

.. contents::

=====
Scope
=====

The scope of this document is to design the features to be implemented for the
Cache component version 1.4. This version will incorporate the following
features and fixes, which will be described in detail in this document:

- #12587: Hierarchic caching for the Cache component

==================================================
#12587: Hierarchic caching for the Cache component
==================================================

The idea behind this feature is to provide hierarchical multi level caching for
the Cache component. Currently the Cache component only supports 1 cache
handler to be asked to restore a certain object. Either the handler returns
cached data for the desired object (hit) or it returns false to indicate that
it does not have valid data (miss). There is no possibility to instruct the
Cache component to search other caches in case of a miss. For this reason,
hierarchic caches will be introduced.

In following, a typical use case will be described to illustrate the need and
behavior of this feature. After that, the proposed class and algorithm design
will be presented.

Use case
========

A typical use case for this feature exists, if several cache locations are
available, which are differently performant and can store a different amount
of items. The following is such a scenario.

3 types of cache are available for an application. The first and fastest level
is covered by a cache that resides in the local memory of the server fulfilling
a request. This cache is extremely fast, because it resides in local memory, but
is therefore also limited to a very low number of objects it can contain
without polluting the local memory too much. The second level cache is a
Memcached, running on a dedicated cache server. This is also quite fast, but
not as fast as the local memory cache, since data needs to be transfered
through a network connection. On the other hand, this cache is larger, since
the server is dedicatedly build for performant caching. The third level of
caching is provided by a file server, which offers the slowest kind of cache.
In contrast, it has the largest storage capability.

In this scenario, the desired behavior would be that the most needed cache
items would be stored in the fastest cache. Cache items which are not that
much, but still often needed could reside in the second cache level and rarely
used items would be stored in the third layer.

Requirements
============

Beside the main requirement, to be able realize hierarchical caching, several
sub-requirements of this exist, which will be summarized in this section. Note
that a fixed target is to not break BC for existing applications in any way and
to avoid code duplication as much as possible. Beside that, too complex
structures need to be avoided to maintain performance.

Hierarchical stacking
---------------------

A way needs to be implemented to put multiple instances of the current
implemented cache storages in a stack to indicate that they represent a
hierarchy. A class to manage such stacks is to be designed and implemented.

An object of this class must take care of:

- **Searching for items recursively through the stack**
  The stacking mechanism needs to search the stack of caches from top to bottom
  before it indicates that a cache item could not be found.
- **Storing new data across the cache stack**
  When a new cache item is stored, it needs to be stored according to the
  strategy chosen for the maintenance of the hierarchy. In addition, it can
  either be stored only in 1 Cache or in several caches at once. For more
  information see the `Cache propagation`_ section.
- **Bubbling restored data up through the cache stack**
  According to the replacement strategy, cache items need to be placed into
  higher levels of the hierarchy, as soon as they get restored from a deeper
  level, to make them available faster on subsequent restore requests. For more
  information see the `Replacement strategies`_ section.

Limiting of cached items
------------------------

The current storage implementations assume that unlimited space is available in
the storage location. Following this philosophy, all cache items would be kept
in the top most storage of the cache stack and the lower storages would not be
needed.

A way must be investigated, how an arbitrary cache storage can be limited by the
number of cache items it stores.

A major problem here is, that this information either needs to persist between
requests or needs to be recalculated in each request. On the one hand, the
latter solution might significantly reduce performance (e.g. for large
file system based caches). On the other hand, the first solution might afford
complex persistence mechanisms for the desired information and might pollute the
cache storages with it.

Replacement strategies
----------------------

As soon as the number of items in a cache exceeds the maximum (see section
`Limiting of cached items`_) and a new item is to be stored, a currently cached
item needs to be replaced. The most favorable approach would be to remove the
item which will be not used for the longest time in the future. Since this is
impossible to know, several established alternatives (e.g. LRU, LFU, ...) exist
to solve the replacement problem. More information about this can be found in
Wikipedia under `cache algorithms`_ and `page replacement algorithms`_.

.. _`cache algorithms`: http://en.wikipedia.org/wiki/Cache_algorithms
.. _`page replacement algorithms`: http://en.wikipedia.org/wiki/Page_replacement_algorithm

A problem with any of the replacement strategies is, that additional
information about a cache item needs to be stored. For example: To realize an
LRU algorithm, the last access time of an item needs to be stored. For LFU, the
number of accesses needs to be stored. The cache storages currently don't
support adding such information and an appropriate place to store this
persistently and efficiently needs to be thought out.

It would be favorable to allow users to decide for a specific replacement
algorithm or to even implement their own strategies.

Cache propagation
-----------------

There are two possibilities to define propagation of cache items through the
stack, where a decision needs to be made for one consistent solution:

Propagate in store
^^^^^^^^^^^^^^^^^^

With this strategy, a newly stored cache item is automatically propagated to
all levels of the cache hierarchy. With this strategy, a newly stored or update
cache item needs to be update in all caches of the hierarchy at once.

This has some advantages and some disadvantages against the second alternative
`Propagate on replacement`_:

Pros:

- Storing of cache items happens in a central place.
- The replacement strategy does not need to take care about downwards
  propagation.

Cons:

- The initial storage of an item lasts longer, since propagation needs to be
  done.
- To purge an item, the item needs to be purged from all storages in the stack,
  that reside deeper than the first cache where the item is found.
- The initial storage of an item may result in a chain reaction of
  replacements, if all storages in the stack reached their maximum number of
  items.

Propagate on replacement
^^^^^^^^^^^^^^^^^^^^^^^^

Using this strategy, a newly stored cache item is only put into the top most
storage in the hierarchy. As soon as it needs to be replaced there, it is
propagated down one level, before being removed from the higher level cache.

Pros:

- The initial storage of a cache item is faster, since it only affects one
  storage. In addition, this should be the fastest storage (the top most).
- Purging of an item does only affect 1 single cache.
- If all storages reached their maximum number of stored items, only a single
  item is bubbled down to the lowest level.

Cons:

- Additional work is to be done on each replacement of a cache item.

Open issues
-----------

This section summarizes misc open issues that need to be solved during the
design and implementation phase.

Locking
^^^^^^^

With hierarchical caching, the complexity of operations that need to be
performed on a storage and between different storages is raised. This might
open the possibility for race conditions in high load environments. To avoid
this, a locking mechanism (or another way to ensure exclusive access) might be
needed.

Design
======

This section is meant to design the enhancements defined by the requirements
section above.

ezcCacheStack
-------------

An object of the ezcCacheStack class is the main instance to provide the
hierarchical stack mechanism. The stack object takes care of managing several
cache storages, the unified access for storing and restoring cache items and
the associated objects needed to realize this.

The class ezcCacheStack extends the class ezcCacheStorage and will therefore be
able to be used with ezcCacheManager. However, this introduces the need to
store all necessary settings for this class in an options object, to enable the
internal delayed initialization mechanism of ezcCacheManager. The class will
only implement the methods required by ezcCacheStorage to be implemented and
will not support additional features of some cache storages, like explicit
searching for items. ::

    class ezcCacheStack extends ezcCacheStorage
    {
        public function __construct( $location, $options );
        public function store( $id, $data, $attributes = array() );
        public function restore( $id, $attributes, $search );
        public function delete( $id, $attributes, $search );
        public function countDataItems( $id, $attributes );
        public function getRemainingLifetime( $id, $attributes );

        public function getStackedCaches();
    }

The $location parameter of the ctor will be ignored by the class, because a
unique location is not required by the stack. The $search parameter for the
restore() and delete() methods is forwarded to the child storages. Aside of
this the parameter instructs the stack to search through all its contained
cache storages, instead of stopping as soon as a fitting item was found in one
of them. 

The requirements defined for cache stacking force cache storages to implement
several additional functionalities. Therefore, a new interface
ezcCacheStackableStorage will be introduced, to define the necessary methods.
This also ensures, that caches are not stacked recursively, since ezcCacheStack
won't implement this interface itself.

Internally, an object of this class is composed from several other objects,
that are defined by the ezcCacheStackOptions class. The getStackedCaches()
method returns the stacked cache storage objects. This method can be used by
user applications to directly influence the cache storages.

.. Note::
   The getStackedCaches() method should in fact not return the storages
   themselves, but their ezcCacheReplacementStrategy facades. This ensures,
   that meta data is kept consistent even if a users accesses the cache.

ezcCacheStackableStorage
------------------------

The interface ezcCacheStackableStorage is used to ensure, that storage classes
that can be stacked implement the necessary functionality. The following
methods are needed: ::

    interface ezcCacheStackableStorage
    {
        restoreMetaInfo();
        storeMetaInfo( array $metaInfo );

        purge();

        lock();
        unlock();
    }

The store-/restoreMetaInfo() methods are needed by the replacement strategy
classes. These need to store different information about the cache items. For
example: For LRU, the last access time per item needs to be stored. This meta
information can be any arbitrary array.

The purge method is needed to make the storage purge all outdated items. In
case a cache storage runs full (determined by the replacement strategy), first
all outdated items will be purged, before items are deleted using the original
strategy. The purge() method needs to return the IDs, attributes and data of
the purged items to allow the replacement and storage strategy objects to
update their information.

.. Note::
   It must be discussed if the number of items to be purged should be submitted
   to purge(). This would allow to stop purging as soon as the desired number
   of items are deleted. On the other hand, purging all possible items at once
   will free more space, which cannot be undesireable.

The lock() and unlock() methods are needed by the stack to ensure complex
operations are inter interferred by concurring requests. The replacement
strategy will lock a storage to perform its operations and unlock it after the
operation has successfully be performed.

ezcCacheStackOptions
--------------------

An object of this class is used to configures the cache stack. It extends the
ezcCacheStorageOptions class, to be compatible with all other mechanisms. The
'ttl' and 'extension' options are ignored, because each of the stacked caches
must be able to implement its own set of options. The following options are
part of this class:

'storageStrategy'
    This option contains a class name, which is to be instantiated to perform
    storage operations in the stack. The class must extend the abstract
    ezcCacheStackStorageStrategy class.
'storages'
    This option is an array of ezcCacheStackStorageConfiguration objects, that
    will be used to define the cache storages contained in the stack. Per
    default, no storages will be defined. In this case, a call to any of the
    methods defined by ezcCacheStorage will result in an exception. 

ezcCacheStackStorageStrategy
----------------------------

Implementations of this abstract base class handle the main storage process
inside an ezcCacheStack object. The abstraction of this strategy allows users
to flexibly decide for better performance or less memory consumption.

The ezcCacheStorageStrategy class defines the following methods: ::

    class ezcCacheStorageStrategy
    {
        public static function store();
        public static function delete();
    }

The methods of a class implementing a storage strategy receive the usual
parameters to store or delete a cache item and the stack of
ezcCacheReplacementStrategy instances in addition. The store() method will use
the given decorated storage and store the given cache item in a certain way.
The delete() method will take care of deleting the defined cache item in every
place it has been stored.

.. Note::
   The abstraction of storage strategies is risky: In case the user messes up a
   cache storage and the ezcCacheStackHighestLevelStorageStrategy is in use,
   cache items might be removed or invalidated without need.

ezcCacheStackHighestLevelStorageStrategy
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Using this storage strategy, a newly stored cache item will only be stored in the
top most cache of the stack. This means, that in case the cache item needs to
be removed from a stack level, it needs to be added to the lower level if this
exists. The storage method behaves like the following pseudo code illustrates: ::

    $highestLevelStorage->store(...);
    $remItems = $highestLevelStorage->getRemovedItems();
    foreach ( $remItems as $item )
    {
        self::store( ..., $nextDeeperLevel );
    }

Since items are only stored in 1 storage at a time, the delete() method needs
to effectively delete an item only in one storage physically. Still, all
storages need to be searched for the desired item to remove, until it is found:
::

    foreach ( $storageStack as $storage ) 
    {
        $storage->delete(...);
    }

Since determining if the desired item is found in a certain cache storage is
too inefficient, the delete() method will be called for every storage of the
stack, while only one storage will effectively perform the deletion.

ezcCacheStackAllLevelStorageStrategy
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In contrast to the ezcCacheStackHighestLevelStorageStrategy, this storage
strategy will store a cache item on all levels of the stack at once. This
consumes more space when an item is stored, but can make the storage process
itself faster, if items need to be replaced often. Replaced items don't need to
be bubbled down to deeper levels if a cache storage runs full. The store()
method will work as follows: ::

    foreach ( $storageStack as $storage ) 
    {
        $storage->store(...);
    }

The delete() method is as simple, but somewhat more ineffective as in the
counterpart replacement strategy. The desired cache item needs to be deleted in
each storage where it is still present and has not been removed, yet. The code
will be exactly the same as in ezcCacheStackHighestLevelStorageStrategy, but
the deletion might physically be performed in all of the storages, instead of
only one.

ezcCacheStackStorageConfiguration
---------------------------------

An instance of this struct like class is used in the 'storages' option of
ezcCacheStackOptions to define the configuration of a single cache storage. It
contains the 3 parameters necessary to instantiate a new cache storage, as well
as additional information, needed by the ezcCacheStack instance and its
aggregated objects. The properties are contained in the class:

'class'
    The class to be instantiated as the storage. This class needs to implement
    the ezcCacheStackableStorage interface, which will be checked for
    correctness via overloading.
'location'
    This parameter is needed to instantiate an ezcCacheStorage object.
'options'
    The options that will be submitted to the storage, when instantiating it.
'itemLimit'
    The maximum number of items to be stored in this cache. Since the size of
    cache items cannot be determined inside PHP, the only way to limit the
    items stored in a cache storage is to use the number of items, stored.
'replacementStrategy'
    This option indicates the replacement strategy, that is to be used with
    this cache. This field must contain a class that implements the
    ezcCacheReplacementStrategy interface.
'freeRate'
    This option is an integer that indicates a percentage value. In case the
    cache storage runs full, this amount of items will be removed. This
    mechanism ensures that running full of a cache does not occur too often.

ezcCacheReplacementStrategy
---------------------------

This interface defines methods that are used to realize the replacement
strategy for a cache. Instances of classes that implement this interface, are
used as facades to ezcCacheStackableStorage. Whenever a cache item is to be
stored, restored or deleted, ezcCacheStack will utilize the replacement
strategy instead of calling the methods on the cache storage directly.

.. Warning::
   To bubble cache items down to lower caches, when removing them from a cache
   storage, the strategy must either return the items in some way or inform the
   deeper caches in another way.

The replacement strategy object will realize the correct replacement of cache
items, in case the storage exceeds the limited number of items to be stored in
it. The interface will define the following methods: ::

    interface ezcCacheReplacementStrategy
    {
        public function __construct( ezcCacheStackableStorage $storage, $limit, $freeRate );
        public function store( $id, $data, $attributes = array() );
        public function restore( $id, $attributes, $search );
        public function delete( $id, $attributes, $search );

        public function countDataItems( $id, $attributes );
        public function getRemainingLifetime( $id, $attributes );

        public function getRemovedItems();
    }

The constructor of a replacement strategy receives a ready to use storage
object, which fulfills all needs  by implementing the ezcCacheStackableStorage
interface. The $limit parameter indicates the maximum number of items to be
stored in the storage. The free rate is a percentage value, that indicates how
many items are to be purged, whenever a cache runs full.

The store() method performs the most complex operation in this case. To
illustrate its working, the following pseudo code is used: ::

    $storage->lock();
    $meta = $storage->restoreMetaInfo();
    $item = $storage->restore( $id );

    if ( $item === false && $meta['itemsStored'] >= $limit )
    {
        // The item was not found and the limit is exceeded. First purge the
        // outdate items, then eventually free more items using the strategy
        // implemented.
        free( $storage, $freeRate );

        // Update the meta information according to the freeing
        update( $meta );
    }

    // There is enough space to store the item now
    $storage->store(...);
    update( $meta );

    $storage->unlock();

The restore() method does not work as complex as the store() method does. Its
algorithm is defined by the following pseudo code: ::

    $storage->lock();
    $item = $storage->restore(...);

    if ( $item !== false )
    {
        // Notice access to this item in meta information
        $meta = $storage->restoreMetaInfo();
        update( $meta );
        $storage->storeMetaInfo( $meta );
    }
    
    $storage->unlock();
    return $item;

The delete() method needs to take care, that deleted items are also removed
from the meta data. The remaining methods just delegate to the underlying
storage in most cases, since their functionality does not affect the
replacement strategy.

.. Note::
   We should offer a method to reset a cache completely (removing all items and
   the meta information), to allow people to reset their cache storages
   completely by an external process.

A replacement strategy should always store its name in the meta data container,
to ensure that a switch between strategies is possible. In case a replacement
strategy receives an invalid meta data structure, it must throw an exception.
The cache must be cleaned completely in this case.

The getRemovedItems() method returns all cache items that have been replaced
during the last method call to store(). The structure of the returned data must
reflect all available information of an item, so that it can be moved to
another cache by an ezcCacheStackStorageStrategy instance. The returned structure
is: ::

    array(
        <id> => ezcCacheReplacedItem(
            $id = <id>,
            $attributes = array(...),
            $data = <data>,
        ),
        <id> => ezcCacheReplacedItem(
            $id = <id>,
            $attributes = array(...),
            $data = <data>,
        ),
        // ...
    )

ezcCacheLruReplacementStrategy
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This replacement strategy works after the Least-Recently-Used algorithm (LRU).
It discards items, which have not been requested (reading or writing) for the
longest time span.

The meta data of this replacement strategy consists of an array, which is
indexed by the IDs of the stored data items assigned to the last access time of
the item. When a new item is added to the cache, its ID is added with the
current time stamp. Each time the data item is read or updated, the time stamp
is actualized. In case the item is removed, the ID is unset in this array.

For the case that the cache runs full, the array of timestamps first needs to
be sorted. Then the first X elements (indicated by $freeRate) will be removed
from the array and the affected items removed from the cache storage
(array_splice()).

ezcCacheLfuReplacementStrategy
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The Least-Frequently-Used algorithm (LFU), in contrast to LRU, stores the
number of accesses of a cache item. In case the cache needs to be freed, those
items are discarded, that have been used least frequently.

The meta data structure is pretty similar to the one of LRU strategy: The cache
item IDs are used as the key, being assigned to the number of accesses to this
item. In case the cache runs full, this list is sorted and the first X elements
(determined by $freeRate) are removed. The cache items assigned to the
determined IDs are deleted from the cache storage.

ezcCacheStorageMetaInformation
------------------------------

This struct is used to represent meta information, that is stored in an
ezcCacheStorage. In addition to the array structure it provides, it contains an
$identifier property that is to be set by the replacement strategy. If a
replacement strategy receives an incorrect meta information object, it must
thrown an exception. ::

    class ezcStorageMetaInformation extends ezcBaseStruct
    {
        public $identifier;

        public $data = array();
    }

A storage is responsible for arbitrary storage of the meta information struct
itself. The APC storage might store it directly, the file system plain storage
might serialize its contents and the file system array storage might convert it
into a complete array.



..
   Local Variables:
   mode: rst
   fill-column: 79
   End: 
   vim: et syn=rst tw=79
